{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (20000, 22)\n",
      "Test (5000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {train.shape}')\n",
    "print(f'Test {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "columns_to_encode = ['Crime_Category', 'Victim_Sex', 'Victim_Descent', 'Status']\n",
    "\n",
    "encoded_data = {col: le.fit_transform(train[col]) for col in columns_to_encode}\n",
    "e_train = train.drop(columns=columns_to_encode).assign(**encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace({None: np.nan, \"\": np.nan})\n",
    "train = train.fillna(value=0)\n",
    "\n",
    "test = test.replace({None: np.nan, \"\": np.nan})\n",
    "test = test.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Victim_Sex'] = train['Victim_Sex'].apply(lambda x: \"Unknown\" if x == 0 else x)\n",
    "train['Victim_Descent'] = train['Victim_Descent'].apply(lambda x: \"Unknown\" if x == 0 else x)\n",
    "\n",
    "test['Victim_Sex'] = test['Victim_Sex'].apply(lambda x: \"Unknown\" if x == 0 else x)\n",
    "test['Victim_Descent'] = test['Victim_Descent'].apply(lambda x: \"Unknown\" if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Location', 'Area_Name', 'Premise_Description', 'Weapon_Description', 'Status_Description'], axis=1, inplace=True)\n",
    "test.drop(columns=['Location', 'Area_Name', 'Premise_Description', 'Weapon_Description', 'Status_Description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "\n",
    "date_format = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "\n",
    "def convert_date(x):\n",
    "  x['Date_Reported'] = pd.to_datetime(x['Date_Reported'], format=date_format)\n",
    "  x['Date_Occurred'] = pd.to_datetime(x['Date_Occurred'], format=date_format)\n",
    "  return x\n",
    "\n",
    "def create_report_delay(x):\n",
    "  x['Report_delay'] = (x['Date_Reported'] - x['Date_Occurred']).dt.days\n",
    "  return x\n",
    "\n",
    "pipeline = Pipeline([\n",
    "  ('convert_date', FunctionTransformer(convert_date, validate=False)),\n",
    "  ('create_report_delay', FunctionTransformer(create_report_delay, validate=False))\n",
    "])\n",
    "\n",
    "train = pipeline.fit_transform(train)\n",
    "test = pipeline.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_features = {\n",
    "    'Day': 'day',\n",
    "    'Month': 'month',\n",
    "    'Year': 'year',\n",
    "    'DOY': 'day_of_year',\n",
    "    'Week': 'weekday'\n",
    "}\n",
    "\n",
    "def extract_date_features(df, date_columns):\n",
    "    for date_col in date_columns:\n",
    "        for feature, attr in date_features.items():\n",
    "            df[f\"{feature}_{date_col.split('_')[1]}\"] = getattr(df[date_col].dt, attr)\n",
    "\n",
    "extract_date_features(train, ['Date_Occurred', 'Date_Reported'])\n",
    "extract_date_features(test, ['Date_Occurred', 'Date_Reported'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Date_Reported','Date_Occurred'], inplace=True)\n",
    "test.drop(columns=['Date_Reported','Date_Occurred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour(time):\n",
    "  time_str = f\"{time:04d}\"\n",
    "  hours = time_str[:2]\n",
    "  return hours\n",
    "\n",
    "def minute(time):\n",
    "  time_str = f\"{time:04d}\"\n",
    "  minute = time_str[2:]\n",
    "  return minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_column(df, time_col):\n",
    "    df[time_col] = df[time_col].astype(int)\n",
    "    df['Hour_Occurred'] = df[time_col].apply(hour).astype(int)\n",
    "    df['Minute_Occurred'] = df[time_col].apply(minute).astype(int)\n",
    "\n",
    "process_time_column(train, 'Time_Occurred')\n",
    "process_time_column(test, 'Time_Occurred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Time_Occurred'], inplace=True)\n",
    "test.drop(columns=['Time_Occurred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Victim_Age'] = train['Victim_Age'].apply(lambda x: 0 if x < 0 else x)\n",
    "test['Victim_Age'] = test['Victim_Age'].apply(lambda x: 0 if x < 0 else x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cs_col(df):\n",
    "    df['Cross_Street'] = df['Cross_Street'].apply(lambda x: 1 if x != 0 else x)\n",
    "    df['Cross_Street'] = df['Cross_Street'].astype(int)\n",
    "\n",
    "convert_cs_col(train)\n",
    "convert_cs_col(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "num_cols = ['Cross_Street', 'Latitude', 'Longitude', 'Area_ID', 'Reporting_District_no','Victim_Age', 'Premise_Code',\n",
    "            'Weapon_Used_Code','Report_delay','Day_Occurred','Month_Occurred', 'Year_Occurred',\n",
    "            'DOY_Occurred', 'Week_Occurred','Day_Reported', 'Month_Reported', 'Year_Reported',\n",
    "            'DOY_Reported','Week_Reported', 'Hour_Occurred', 'Minute_Occurred']\n",
    "\n",
    "cat_cols = ['Part 1-2', 'Victim_Sex', 'Victim_Descent', 'Status']\n",
    "\n",
    "col_trans = ColumnTransformer([\n",
    "    ('scalar', MinMaxScaler(), num_cols),\n",
    "    ('ohe', OneHotEncoder(), cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed = col_trans.fit_transform(train)\n",
    "col_names_train = col_trans.get_feature_names_out()\n",
    "\n",
    "ccn_train = []\n",
    "for col_name in col_names_train:\n",
    "  if \"__\" in col_name:\n",
    "    cn = col_name.split(\"__\")[1]\n",
    "    ccn_train.append(cn)\n",
    "  else:\n",
    "    ccn_train.append(col_name)  \n",
    "\n",
    "train_transformed = pd.DataFrame(train_transformed, columns=ccn_train)\n",
    "train = pd.concat([train.drop(columns=num_cols+cat_cols), train_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = col_trans.fit_transform(test)\n",
    "col_names_test = col_trans.get_feature_names_out()\n",
    "\n",
    "ccn_test = []\n",
    "for col_name in col_names_test:\n",
    "  if \"__\" in col_name:\n",
    "    cn = col_name.split(\"__\")[1]\n",
    "    ccn_test.append(cn)\n",
    "  else:\n",
    "    ccn_test.append(col_name)\n",
    "\n",
    "test_transformed = pd.DataFrame(test_transformed, columns=ccn_test)\n",
    "test = pd.concat([test.drop(columns=num_cols+cat_cols), test_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Modus_Operandi'] = train['Modus_Operandi'].astype(str)\n",
    "train['Modus_Operandi'] = train['Modus_Operandi'].apply(lambda x: x.split())\n",
    "\n",
    "test['Modus_Operandi'] = test['Modus_Operandi'].astype(str)\n",
    "test['Modus_Operandi'] = test['Modus_Operandi'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "modus_encoded = mlb.fit_transform(train['Modus_Operandi'])\n",
    "modus_encoded_train = pd.DataFrame(modus_encoded, columns=mlb.classes_)\n",
    "\n",
    "modus_encoded_train.index = train.index\n",
    "train = pd.concat([train, modus_encoded_train], axis=1)\n",
    "\n",
    "me = mlb.fit_transform(test['Modus_Operandi'])\n",
    "modus_encoded_test = pd.DataFrame(me, columns=mlb.classes_)\n",
    "\n",
    "modus_encoded_test.index = test.index\n",
    "test = pd.concat([test, modus_encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['Modus_Operandi'], inplace=True)\n",
    "test.drop(columns=['Modus_Operandi'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(set(train.columns) | set(test.columns))\n",
    "\n",
    "train = train.reindex(columns=all_columns, fill_value=0)\n",
    "test = test.reindex(columns=all_columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns\n",
    "f_test = test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test.drop(columns=['Crime_Category'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=['Crime_Category'])\n",
    "y_train = train['Crime_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quock\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=0)\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "                           \"ID\": np.arange(1,5001), \n",
    "                           \"Crime_Category\": y_pred,\n",
    "                          }) \n",
    "\n",
    "submission.to_csv('../data/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
